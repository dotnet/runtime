// Licensed to the .NET Foundation under one or more agreements.
// The .NET Foundation licenses this file to you under the MIT license.

/////////////////////////////////////////////////////////////////////////////
////
// This file was auto-generated by a tool at 2025-09-18 12:31:55
//
// It is recommended you DO NOT directly edit this file but instead edit
// the code-generator that generated this source file instead.
/////////////////////////////////////////////////////////////////////////////

#ifndef BITONIC_SORT_NEON_UINT32_T_H
#define BITONIC_SORT_NEON_UINT32_T_H

#include "bitonic_sort.h"
#include <arm_neon.h>

namespace vxsort {
namespace smallsort {


template<> struct bitonic<uint32_t, NEON> {
    static const int N = 4;
    static constexpr uint32_t MAX = std::numeric_limits<uint32_t>::max();

    static const uint32x4_t idx;
    static const uint32x4_t maxv;
    static const uint32_t mask1Array[];
    static const uint32_t mask2Array[];
public:

    static INLINE void sort_01v_ascending(uint32x4_t& d01) {

        // Sort (0,1) and (2,3)
        uint32x4_t b   = vrev64q_u32(d01);
        uint32x4_t mn1 = vminq_u32(d01, b);
        uint32x4_t mx1 = vmaxq_u32(d01, b);
        uint32x4x2_t t1 = vtrnq_u32(mn1, mx1);
        d01 = t1.val[0];

        // Sort (0,2) and (1,3)
        uint32x4_t sh2  = vextq_u32(d01, d01, 2);
        uint32x4_t mn2  = vminq_u32(d01, sh2);
        uint32x4_t mx2  = vmaxq_u32(d01, sh2);
        d01 = vcombine_u32(vget_low_u32(mn2), vget_high_u32(mx2));

        // Sort (1,2)
        uint32x4_t sh1   = vextq_u32(d01, d01, 1);
        uint32x4_t mn12  = vminq_u32(d01, sh1);
        uint32x4_t mx12  = vmaxq_u32(d01, sh1);
        uint32x4_t rot = vextq_u32(mx12, mx12, 3);
        const uint32x4_t mask1 = vld1q_u32(mask1Array);
        const uint32x4_t mask2 = vld1q_u32(mask2Array);
        d01 = vbslq_u32(mask1, mn12, d01);
        d01 = vbslq_u32(mask2, rot, d01);
    }

    static INLINE void sort_01v_merge_ascending(uint32x4_t& d01) {

        // Sort (0,1) and (2,3)
        uint32x4_t b   = vrev64q_u32(d01);
        uint32x4_t mn1 = vminq_u32(d01, b);
        uint32x4_t mx1 = vmaxq_u32(d01, b);
        uint32x4x2_t t1 = vtrnq_u32(mn1, mx1);
        d01 = t1.val[0];

        // Sort (0,2) and (1,3)
        uint32x4_t sh2  = vextq_u32(d01, d01, 2);
        uint32x4_t mn2  = vminq_u32(d01, sh2);
        uint32x4_t mx2  = vmaxq_u32(d01, sh2);
        d01 = vcombine_u32(vget_low_u32(mn2), vget_high_u32(mx2));

        // Sort (1,2)
        uint32x4_t sh1   = vextq_u32(d01, d01, 1);
        uint32x4_t mn12  = vminq_u32(d01, sh1);
        uint32x4_t mx12  = vmaxq_u32(d01, sh1);
        uint32x4_t rot = vextq_u32(mx12, mx12, 3);
        const uint32x4_t mask1 = vld1q_u32(mask1Array);
        const uint32x4_t mask2 = vld1q_u32(mask2Array);
        d01 = vbslq_u32(mask1, mn12, d01);
        d01 = vbslq_u32(mask2, rot, d01);
    }

    static INLINE void sort_01v_descending(uint32x4_t& d01) {

        // Sort (0,1) and (2,3)
        uint32x4_t b   = vrev64q_u32(d01);
        uint32x4_t mn1 = vminq_u32(d01, b);
        uint32x4_t mx1 = vmaxq_u32(d01, b);
        uint32x4x2_t t1 = vtrnq_u32(mx1, mn1);
        d01 = t1.val[0];

        // Sort (0,2) and (1,3)
        uint32x4_t sh2  = vextq_u32(d01, d01, 2);
        uint32x4_t mn2  = vminq_u32(d01, sh2);
        uint32x4_t mx2  = vmaxq_u32(d01, sh2);
        d01 = vcombine_u32(vget_low_u32(mx2), vget_high_u32(mn2));

        // Sort (1,2)
        uint32x4_t sh1   = vextq_u32(d01, d01, 1);
        uint32x4_t mn12  = vminq_u32(d01, sh1);
        uint32x4_t mx12  = vmaxq_u32(d01, sh1);
        uint32x4_t rot = vextq_u32(mn12, mn12, 3);
        const uint32x4_t mask1 = vld1q_u32(mask1Array);
        const uint32x4_t mask2 = vld1q_u32(mask2Array);
        d01 = vbslq_u32(mask1, mx12, d01);
        d01 = vbslq_u32(mask2, rot, d01);
    }

    static INLINE void sort_01v_merge_descending(uint32x4_t& d01) {

        // Sort (0,1) and (2,3)
        uint32x4_t b   = vrev64q_u32(d01);
        uint32x4_t mn1 = vminq_u32(d01, b);
        uint32x4_t mx1 = vmaxq_u32(d01, b);
        uint32x4x2_t t1 = vtrnq_u32(mx1, mn1);
        d01 = t1.val[0];

        // Sort (0,2) and (1,3)
        uint32x4_t sh2  = vextq_u32(d01, d01, 2);
        uint32x4_t mn2  = vminq_u32(d01, sh2);
        uint32x4_t mx2  = vmaxq_u32(d01, sh2);
        d01 = vcombine_u32(vget_low_u32(mx2), vget_high_u32(mn2));

        // Sort (1,2)
        uint32x4_t sh1   = vextq_u32(d01, d01, 1);
        uint32x4_t mn12  = vminq_u32(d01, sh1);
        uint32x4_t mx12  = vmaxq_u32(d01, sh1);
        uint32x4_t rot = vextq_u32(mn12, mn12, 3);
        const uint32x4_t mask1 = vld1q_u32(mask1Array);
        const uint32x4_t mask2 = vld1q_u32(mask2Array);
        d01 = vbslq_u32(mask1, mx12, d01);
        d01 = vbslq_u32(mask2, rot, d01);
    }

    static INLINE void sort_02v_ascending(uint32x4_t& d01, uint32x4_t& d02) {
        uint32x4_t tmp;

        sort_01v_ascending(d01);
        sort_01v_descending(d02);

        tmp = d02;
        d02 = vmaxq_u32(d01, d02);
        d01 = vminq_u32(d01, tmp);

        sort_01v_merge_ascending(d01);
        sort_01v_merge_ascending(d02);
    }

    static INLINE void sort_02v_descending(uint32x4_t& d01, uint32x4_t& d02) {
        uint32x4_t tmp;

        sort_01v_descending(d01);
        sort_01v_ascending(d02);

        tmp = d02;
        d02 = vmaxq_u32(d01, d02);
        d01 = vminq_u32(d01, tmp);

        sort_01v_merge_descending(d01);
        sort_01v_merge_descending(d02);
    }

    static INLINE void sort_02v_merge_ascending(uint32x4_t& d01, uint32x4_t& d02) {
        uint32x4_t tmp;

        tmp = d01;
        d01 = vminq_u32(d02, d01);
        d02 = vmaxq_u32(d02, tmp);

        sort_01v_merge_ascending(d01);
        sort_01v_merge_ascending(d02);
    }

    static INLINE void sort_02v_merge_descending(uint32x4_t& d01, uint32x4_t& d02) {
        uint32x4_t tmp;

        tmp = d01;
        d01 = vminq_u32(d02, d01);
        d02 = vmaxq_u32(d02, tmp);

        sort_01v_merge_descending(d01);
        sort_01v_merge_descending(d02);
    }

    static INLINE void sort_03v_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03) {
        uint32x4_t tmp;

        sort_02v_ascending(d01, d02);
        sort_01v_descending(d03);

        tmp = d03;
        d03 = vmaxq_u32(d02, d03);
        d02 = vminq_u32(d02, tmp);

        sort_02v_merge_ascending(d01, d02);
        sort_01v_merge_ascending(d03);
    }

    static INLINE void sort_03v_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03) {
        uint32x4_t tmp;

        sort_02v_descending(d01, d02);
        sort_01v_ascending(d03);

        tmp = d03;
        d03 = vmaxq_u32(d02, d03);
        d02 = vminq_u32(d02, tmp);

        sort_02v_merge_descending(d01, d02);
        sort_01v_merge_descending(d03);
    }

    static INLINE void sort_03v_merge_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03) {
        uint32x4_t tmp;

        tmp = d01;
        d01 = vminq_u32(d03, d01);
        d03 = vmaxq_u32(d03, tmp);

        sort_02v_merge_ascending(d01, d02);
        sort_01v_merge_ascending(d03);
    }

    static INLINE void sort_03v_merge_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03) {
        uint32x4_t tmp;

        tmp = d01;
        d01 = vminq_u32(d03, d01);
        d03 = vmaxq_u32(d03, tmp);

        sort_02v_merge_descending(d01, d02);
        sort_01v_merge_descending(d03);
    }

    static INLINE void sort_04v_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04) {
        uint32x4_t tmp;

        sort_02v_ascending(d01, d02);
        sort_02v_descending(d03, d04);

        tmp = d03;
        d03 = vmaxq_u32(d02, d03);
        d02 = vminq_u32(d02, tmp);

        tmp = d04;
        d04 = vmaxq_u32(d01, d04);
        d01 = vminq_u32(d01, tmp);

        sort_02v_merge_ascending(d01, d02);
        sort_02v_merge_ascending(d03, d04);
    }

    static INLINE void sort_04v_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04) {
        uint32x4_t tmp;

        sort_02v_descending(d01, d02);
        sort_02v_ascending(d03, d04);

        tmp = d03;
        d03 = vmaxq_u32(d02, d03);
        d02 = vminq_u32(d02, tmp);

        tmp = d04;
        d04 = vmaxq_u32(d01, d04);
        d01 = vminq_u32(d01, tmp);

        sort_02v_merge_descending(d01, d02);
        sort_02v_merge_descending(d03, d04);
    }

    static INLINE void sort_04v_merge_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04) {
        uint32x4_t tmp;

        tmp = d01;
        d01 = vminq_u32(d03, d01);
        d03 = vmaxq_u32(d03, tmp);

        tmp = d02;
        d02 = vminq_u32(d04, d02);
        d04 = vmaxq_u32(d04, tmp);

        sort_02v_merge_ascending(d01, d02);
        sort_02v_merge_ascending(d03, d04);
    }

    static INLINE void sort_04v_merge_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04) {
        uint32x4_t tmp;

        tmp = d01;
        d01 = vminq_u32(d03, d01);
        d03 = vmaxq_u32(d03, tmp);

        tmp = d02;
        d02 = vminq_u32(d04, d02);
        d04 = vmaxq_u32(d04, tmp);

        sort_02v_merge_descending(d01, d02);
        sort_02v_merge_descending(d03, d04);
    }

    static INLINE void sort_05v_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05) {
        uint32x4_t tmp;

        sort_04v_ascending(d01, d02, d03, d04);
        sort_01v_descending(d05);

        tmp = d05;
        d05 = vmaxq_u32(d04, d05);
        d04 = vminq_u32(d04, tmp);

        sort_04v_merge_ascending(d01, d02, d03, d04);
        sort_01v_merge_ascending(d05);
    }

    static INLINE void sort_05v_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05) {
        uint32x4_t tmp;

        sort_04v_descending(d01, d02, d03, d04);
        sort_01v_ascending(d05);

        tmp = d05;
        d05 = vmaxq_u32(d04, d05);
        d04 = vminq_u32(d04, tmp);

        sort_04v_merge_descending(d01, d02, d03, d04);
        sort_01v_merge_descending(d05);
    }

    static INLINE void sort_05v_merge_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05) {
        uint32x4_t tmp;

        tmp = d01;
        d01 = vminq_u32(d05, d01);
        d05 = vmaxq_u32(d05, tmp);

        sort_04v_merge_ascending(d01, d02, d03, d04);
        sort_01v_merge_ascending(d05);
    }

    static INLINE void sort_05v_merge_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05) {
        uint32x4_t tmp;

        tmp = d01;
        d01 = vminq_u32(d05, d01);
        d05 = vmaxq_u32(d05, tmp);

        sort_04v_merge_descending(d01, d02, d03, d04);
        sort_01v_merge_descending(d05);
    }

    static INLINE void sort_06v_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06) {
        uint32x4_t tmp;

        sort_04v_ascending(d01, d02, d03, d04);
        sort_02v_descending(d05, d06);

        tmp = d05;
        d05 = vmaxq_u32(d04, d05);
        d04 = vminq_u32(d04, tmp);

        tmp = d06;
        d06 = vmaxq_u32(d03, d06);
        d03 = vminq_u32(d03, tmp);

        sort_04v_merge_ascending(d01, d02, d03, d04);
        sort_02v_merge_ascending(d05, d06);
    }

    static INLINE void sort_06v_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06) {
        uint32x4_t tmp;

        sort_04v_descending(d01, d02, d03, d04);
        sort_02v_ascending(d05, d06);

        tmp = d05;
        d05 = vmaxq_u32(d04, d05);
        d04 = vminq_u32(d04, tmp);

        tmp = d06;
        d06 = vmaxq_u32(d03, d06);
        d03 = vminq_u32(d03, tmp);

        sort_04v_merge_descending(d01, d02, d03, d04);
        sort_02v_merge_descending(d05, d06);
    }

    static INLINE void sort_06v_merge_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06) {
        uint32x4_t tmp;

        tmp = d01;
        d01 = vminq_u32(d05, d01);
        d05 = vmaxq_u32(d05, tmp);

        tmp = d02;
        d02 = vminq_u32(d06, d02);
        d06 = vmaxq_u32(d06, tmp);

        sort_04v_merge_ascending(d01, d02, d03, d04);
        sort_02v_merge_ascending(d05, d06);
    }

    static INLINE void sort_06v_merge_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06) {
        uint32x4_t tmp;

        tmp = d01;
        d01 = vminq_u32(d05, d01);
        d05 = vmaxq_u32(d05, tmp);

        tmp = d02;
        d02 = vminq_u32(d06, d02);
        d06 = vmaxq_u32(d06, tmp);

        sort_04v_merge_descending(d01, d02, d03, d04);
        sort_02v_merge_descending(d05, d06);
    }

    static INLINE void sort_07v_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07) {
        uint32x4_t tmp;

        sort_04v_ascending(d01, d02, d03, d04);
        sort_03v_descending(d05, d06, d07);

        tmp = d05;
        d05 = vmaxq_u32(d04, d05);
        d04 = vminq_u32(d04, tmp);

        tmp = d06;
        d06 = vmaxq_u32(d03, d06);
        d03 = vminq_u32(d03, tmp);

        tmp = d07;
        d07 = vmaxq_u32(d02, d07);
        d02 = vminq_u32(d02, tmp);

        sort_04v_merge_ascending(d01, d02, d03, d04);
        sort_03v_merge_ascending(d05, d06, d07);
    }

    static INLINE void sort_07v_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07) {
        uint32x4_t tmp;

        sort_04v_descending(d01, d02, d03, d04);
        sort_03v_ascending(d05, d06, d07);

        tmp = d05;
        d05 = vmaxq_u32(d04, d05);
        d04 = vminq_u32(d04, tmp);

        tmp = d06;
        d06 = vmaxq_u32(d03, d06);
        d03 = vminq_u32(d03, tmp);

        tmp = d07;
        d07 = vmaxq_u32(d02, d07);
        d02 = vminq_u32(d02, tmp);

        sort_04v_merge_descending(d01, d02, d03, d04);
        sort_03v_merge_descending(d05, d06, d07);
    }

    static INLINE void sort_07v_merge_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07) {
        uint32x4_t tmp;

        tmp = d01;
        d01 = vminq_u32(d05, d01);
        d05 = vmaxq_u32(d05, tmp);

        tmp = d02;
        d02 = vminq_u32(d06, d02);
        d06 = vmaxq_u32(d06, tmp);

        tmp = d03;
        d03 = vminq_u32(d07, d03);
        d07 = vmaxq_u32(d07, tmp);

        sort_04v_merge_ascending(d01, d02, d03, d04);
        sort_03v_merge_ascending(d05, d06, d07);
    }

    static INLINE void sort_07v_merge_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07) {
        uint32x4_t tmp;

        tmp = d01;
        d01 = vminq_u32(d05, d01);
        d05 = vmaxq_u32(d05, tmp);

        tmp = d02;
        d02 = vminq_u32(d06, d02);
        d06 = vmaxq_u32(d06, tmp);

        tmp = d03;
        d03 = vminq_u32(d07, d03);
        d07 = vmaxq_u32(d07, tmp);

        sort_04v_merge_descending(d01, d02, d03, d04);
        sort_03v_merge_descending(d05, d06, d07);
    }

    static INLINE void sort_08v_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08) {
        uint32x4_t tmp;

        sort_04v_ascending(d01, d02, d03, d04);
        sort_04v_descending(d05, d06, d07, d08);

        tmp = d05;
        d05 = vmaxq_u32(d04, d05);
        d04 = vminq_u32(d04, tmp);

        tmp = d06;
        d06 = vmaxq_u32(d03, d06);
        d03 = vminq_u32(d03, tmp);

        tmp = d07;
        d07 = vmaxq_u32(d02, d07);
        d02 = vminq_u32(d02, tmp);

        tmp = d08;
        d08 = vmaxq_u32(d01, d08);
        d01 = vminq_u32(d01, tmp);

        sort_04v_merge_ascending(d01, d02, d03, d04);
        sort_04v_merge_ascending(d05, d06, d07, d08);
    }

    static INLINE void sort_08v_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08) {
        uint32x4_t tmp;

        sort_04v_descending(d01, d02, d03, d04);
        sort_04v_ascending(d05, d06, d07, d08);

        tmp = d05;
        d05 = vmaxq_u32(d04, d05);
        d04 = vminq_u32(d04, tmp);

        tmp = d06;
        d06 = vmaxq_u32(d03, d06);
        d03 = vminq_u32(d03, tmp);

        tmp = d07;
        d07 = vmaxq_u32(d02, d07);
        d02 = vminq_u32(d02, tmp);

        tmp = d08;
        d08 = vmaxq_u32(d01, d08);
        d01 = vminq_u32(d01, tmp);

        sort_04v_merge_descending(d01, d02, d03, d04);
        sort_04v_merge_descending(d05, d06, d07, d08);
    }

    static INLINE void sort_08v_merge_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08) {
        uint32x4_t tmp;

        tmp = d01;
        d01 = vminq_u32(d05, d01);
        d05 = vmaxq_u32(d05, tmp);

        tmp = d02;
        d02 = vminq_u32(d06, d02);
        d06 = vmaxq_u32(d06, tmp);

        tmp = d03;
        d03 = vminq_u32(d07, d03);
        d07 = vmaxq_u32(d07, tmp);

        tmp = d04;
        d04 = vminq_u32(d08, d04);
        d08 = vmaxq_u32(d08, tmp);

        sort_04v_merge_ascending(d01, d02, d03, d04);
        sort_04v_merge_ascending(d05, d06, d07, d08);
    }

    static INLINE void sort_08v_merge_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08) {
        uint32x4_t tmp;

        tmp = d01;
        d01 = vminq_u32(d05, d01);
        d05 = vmaxq_u32(d05, tmp);

        tmp = d02;
        d02 = vminq_u32(d06, d02);
        d06 = vmaxq_u32(d06, tmp);

        tmp = d03;
        d03 = vminq_u32(d07, d03);
        d07 = vmaxq_u32(d07, tmp);

        tmp = d04;
        d04 = vminq_u32(d08, d04);
        d08 = vmaxq_u32(d08, tmp);

        sort_04v_merge_descending(d01, d02, d03, d04);
        sort_04v_merge_descending(d05, d06, d07, d08);
    }

    static INLINE void sort_09v_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09) {
        uint32x4_t tmp;

        sort_08v_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_01v_descending(d09);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        sort_08v_merge_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_01v_merge_ascending(d09);
    }

    static INLINE void sort_09v_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09) {
        uint32x4_t tmp;

        sort_08v_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_01v_ascending(d09);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        sort_08v_merge_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_01v_merge_descending(d09);
    }

    static INLINE void sort_10v_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09, uint32x4_t& d10) {
        uint32x4_t tmp;

        sort_08v_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_02v_descending(d09, d10);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        tmp = d10;
        d10 = vmaxq_u32(d07, d10);
        d07 = vminq_u32(d07, tmp);

        sort_08v_merge_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_02v_merge_ascending(d09, d10);
    }

    static INLINE void sort_10v_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09, uint32x4_t& d10) {
        uint32x4_t tmp;

        sort_08v_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_02v_ascending(d09, d10);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        tmp = d10;
        d10 = vmaxq_u32(d07, d10);
        d07 = vminq_u32(d07, tmp);

        sort_08v_merge_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_02v_merge_descending(d09, d10);
    }

    static INLINE void sort_11v_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09, uint32x4_t& d10, uint32x4_t& d11) {
        uint32x4_t tmp;

        sort_08v_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_03v_descending(d09, d10, d11);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        tmp = d10;
        d10 = vmaxq_u32(d07, d10);
        d07 = vminq_u32(d07, tmp);

        tmp = d11;
        d11 = vmaxq_u32(d06, d11);
        d06 = vminq_u32(d06, tmp);

        sort_08v_merge_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_03v_merge_ascending(d09, d10, d11);
    }

    static INLINE void sort_11v_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09, uint32x4_t& d10, uint32x4_t& d11) {
        uint32x4_t tmp;

        sort_08v_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_03v_ascending(d09, d10, d11);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        tmp = d10;
        d10 = vmaxq_u32(d07, d10);
        d07 = vminq_u32(d07, tmp);

        tmp = d11;
        d11 = vmaxq_u32(d06, d11);
        d06 = vminq_u32(d06, tmp);

        sort_08v_merge_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_03v_merge_descending(d09, d10, d11);
    }

    static INLINE void sort_12v_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09, uint32x4_t& d10, uint32x4_t& d11, uint32x4_t& d12) {
        uint32x4_t tmp;

        sort_08v_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_04v_descending(d09, d10, d11, d12);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        tmp = d10;
        d10 = vmaxq_u32(d07, d10);
        d07 = vminq_u32(d07, tmp);

        tmp = d11;
        d11 = vmaxq_u32(d06, d11);
        d06 = vminq_u32(d06, tmp);

        tmp = d12;
        d12 = vmaxq_u32(d05, d12);
        d05 = vminq_u32(d05, tmp);

        sort_08v_merge_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_04v_merge_ascending(d09, d10, d11, d12);
    }

    static INLINE void sort_12v_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09, uint32x4_t& d10, uint32x4_t& d11, uint32x4_t& d12) {
        uint32x4_t tmp;

        sort_08v_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_04v_ascending(d09, d10, d11, d12);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        tmp = d10;
        d10 = vmaxq_u32(d07, d10);
        d07 = vminq_u32(d07, tmp);

        tmp = d11;
        d11 = vmaxq_u32(d06, d11);
        d06 = vminq_u32(d06, tmp);

        tmp = d12;
        d12 = vmaxq_u32(d05, d12);
        d05 = vminq_u32(d05, tmp);

        sort_08v_merge_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_04v_merge_descending(d09, d10, d11, d12);
    }

    static INLINE void sort_13v_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09, uint32x4_t& d10, uint32x4_t& d11, uint32x4_t& d12, uint32x4_t& d13) {
        uint32x4_t tmp;

        sort_08v_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_05v_descending(d09, d10, d11, d12, d13);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        tmp = d10;
        d10 = vmaxq_u32(d07, d10);
        d07 = vminq_u32(d07, tmp);

        tmp = d11;
        d11 = vmaxq_u32(d06, d11);
        d06 = vminq_u32(d06, tmp);

        tmp = d12;
        d12 = vmaxq_u32(d05, d12);
        d05 = vminq_u32(d05, tmp);

        tmp = d13;
        d13 = vmaxq_u32(d04, d13);
        d04 = vminq_u32(d04, tmp);

        sort_08v_merge_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_05v_merge_ascending(d09, d10, d11, d12, d13);
    }

    static INLINE void sort_13v_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09, uint32x4_t& d10, uint32x4_t& d11, uint32x4_t& d12, uint32x4_t& d13) {
        uint32x4_t tmp;

        sort_08v_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_05v_ascending(d09, d10, d11, d12, d13);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        tmp = d10;
        d10 = vmaxq_u32(d07, d10);
        d07 = vminq_u32(d07, tmp);

        tmp = d11;
        d11 = vmaxq_u32(d06, d11);
        d06 = vminq_u32(d06, tmp);

        tmp = d12;
        d12 = vmaxq_u32(d05, d12);
        d05 = vminq_u32(d05, tmp);

        tmp = d13;
        d13 = vmaxq_u32(d04, d13);
        d04 = vminq_u32(d04, tmp);

        sort_08v_merge_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_05v_merge_descending(d09, d10, d11, d12, d13);
    }

    static INLINE void sort_14v_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09, uint32x4_t& d10, uint32x4_t& d11, uint32x4_t& d12, uint32x4_t& d13, uint32x4_t& d14) {
        uint32x4_t tmp;

        sort_08v_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_06v_descending(d09, d10, d11, d12, d13, d14);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        tmp = d10;
        d10 = vmaxq_u32(d07, d10);
        d07 = vminq_u32(d07, tmp);

        tmp = d11;
        d11 = vmaxq_u32(d06, d11);
        d06 = vminq_u32(d06, tmp);

        tmp = d12;
        d12 = vmaxq_u32(d05, d12);
        d05 = vminq_u32(d05, tmp);

        tmp = d13;
        d13 = vmaxq_u32(d04, d13);
        d04 = vminq_u32(d04, tmp);

        tmp = d14;
        d14 = vmaxq_u32(d03, d14);
        d03 = vminq_u32(d03, tmp);

        sort_08v_merge_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_06v_merge_ascending(d09, d10, d11, d12, d13, d14);
    }

    static INLINE void sort_14v_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09, uint32x4_t& d10, uint32x4_t& d11, uint32x4_t& d12, uint32x4_t& d13, uint32x4_t& d14) {
        uint32x4_t tmp;

        sort_08v_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_06v_ascending(d09, d10, d11, d12, d13, d14);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        tmp = d10;
        d10 = vmaxq_u32(d07, d10);
        d07 = vminq_u32(d07, tmp);

        tmp = d11;
        d11 = vmaxq_u32(d06, d11);
        d06 = vminq_u32(d06, tmp);

        tmp = d12;
        d12 = vmaxq_u32(d05, d12);
        d05 = vminq_u32(d05, tmp);

        tmp = d13;
        d13 = vmaxq_u32(d04, d13);
        d04 = vminq_u32(d04, tmp);

        tmp = d14;
        d14 = vmaxq_u32(d03, d14);
        d03 = vminq_u32(d03, tmp);

        sort_08v_merge_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_06v_merge_descending(d09, d10, d11, d12, d13, d14);
    }

    static INLINE void sort_15v_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09, uint32x4_t& d10, uint32x4_t& d11, uint32x4_t& d12, uint32x4_t& d13, uint32x4_t& d14, uint32x4_t& d15) {
        uint32x4_t tmp;

        sort_08v_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_07v_descending(d09, d10, d11, d12, d13, d14, d15);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        tmp = d10;
        d10 = vmaxq_u32(d07, d10);
        d07 = vminq_u32(d07, tmp);

        tmp = d11;
        d11 = vmaxq_u32(d06, d11);
        d06 = vminq_u32(d06, tmp);

        tmp = d12;
        d12 = vmaxq_u32(d05, d12);
        d05 = vminq_u32(d05, tmp);

        tmp = d13;
        d13 = vmaxq_u32(d04, d13);
        d04 = vminq_u32(d04, tmp);

        tmp = d14;
        d14 = vmaxq_u32(d03, d14);
        d03 = vminq_u32(d03, tmp);

        tmp = d15;
        d15 = vmaxq_u32(d02, d15);
        d02 = vminq_u32(d02, tmp);

        sort_08v_merge_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_07v_merge_ascending(d09, d10, d11, d12, d13, d14, d15);
    }

    static INLINE void sort_15v_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09, uint32x4_t& d10, uint32x4_t& d11, uint32x4_t& d12, uint32x4_t& d13, uint32x4_t& d14, uint32x4_t& d15) {
        uint32x4_t tmp;

        sort_08v_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_07v_ascending(d09, d10, d11, d12, d13, d14, d15);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        tmp = d10;
        d10 = vmaxq_u32(d07, d10);
        d07 = vminq_u32(d07, tmp);

        tmp = d11;
        d11 = vmaxq_u32(d06, d11);
        d06 = vminq_u32(d06, tmp);

        tmp = d12;
        d12 = vmaxq_u32(d05, d12);
        d05 = vminq_u32(d05, tmp);

        tmp = d13;
        d13 = vmaxq_u32(d04, d13);
        d04 = vminq_u32(d04, tmp);

        tmp = d14;
        d14 = vmaxq_u32(d03, d14);
        d03 = vminq_u32(d03, tmp);

        tmp = d15;
        d15 = vmaxq_u32(d02, d15);
        d02 = vminq_u32(d02, tmp);

        sort_08v_merge_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_07v_merge_descending(d09, d10, d11, d12, d13, d14, d15);
    }

    static INLINE void sort_16v_ascending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09, uint32x4_t& d10, uint32x4_t& d11, uint32x4_t& d12, uint32x4_t& d13, uint32x4_t& d14, uint32x4_t& d15, uint32x4_t& d16) {
        uint32x4_t tmp;

        sort_08v_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_08v_descending(d09, d10, d11, d12, d13, d14, d15, d16);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        tmp = d10;
        d10 = vmaxq_u32(d07, d10);
        d07 = vminq_u32(d07, tmp);

        tmp = d11;
        d11 = vmaxq_u32(d06, d11);
        d06 = vminq_u32(d06, tmp);

        tmp = d12;
        d12 = vmaxq_u32(d05, d12);
        d05 = vminq_u32(d05, tmp);

        tmp = d13;
        d13 = vmaxq_u32(d04, d13);
        d04 = vminq_u32(d04, tmp);

        tmp = d14;
        d14 = vmaxq_u32(d03, d14);
        d03 = vminq_u32(d03, tmp);

        tmp = d15;
        d15 = vmaxq_u32(d02, d15);
        d02 = vminq_u32(d02, tmp);

        tmp = d16;
        d16 = vmaxq_u32(d01, d16);
        d01 = vminq_u32(d01, tmp);

        sort_08v_merge_ascending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_08v_merge_ascending(d09, d10, d11, d12, d13, d14, d15, d16);
    }

    static INLINE void sort_16v_descending(uint32x4_t& d01, uint32x4_t& d02, uint32x4_t& d03, uint32x4_t& d04, uint32x4_t& d05, uint32x4_t& d06, uint32x4_t& d07, uint32x4_t& d08, uint32x4_t& d09, uint32x4_t& d10, uint32x4_t& d11, uint32x4_t& d12, uint32x4_t& d13, uint32x4_t& d14, uint32x4_t& d15, uint32x4_t& d16) {
        uint32x4_t tmp;

        sort_08v_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_08v_ascending(d09, d10, d11, d12, d13, d14, d15, d16);

        tmp = d09;
        d09 = vmaxq_u32(d08, d09);
        d08 = vminq_u32(d08, tmp);

        tmp = d10;
        d10 = vmaxq_u32(d07, d10);
        d07 = vminq_u32(d07, tmp);

        tmp = d11;
        d11 = vmaxq_u32(d06, d11);
        d06 = vminq_u32(d06, tmp);

        tmp = d12;
        d12 = vmaxq_u32(d05, d12);
        d05 = vminq_u32(d05, tmp);

        tmp = d13;
        d13 = vmaxq_u32(d04, d13);
        d04 = vminq_u32(d04, tmp);

        tmp = d14;
        d14 = vmaxq_u32(d03, d14);
        d03 = vminq_u32(d03, tmp);

        tmp = d15;
        d15 = vmaxq_u32(d02, d15);
        d02 = vminq_u32(d02, tmp);

        tmp = d16;
        d16 = vmaxq_u32(d01, d16);
        d01 = vminq_u32(d01, tmp);

        sort_08v_merge_descending(d01, d02, d03, d04, d05, d06, d07, d08);
        sort_08v_merge_descending(d09, d10, d11, d12, d13, d14, d15, d16);
    }


    static NOINLINE void sort_01v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d01 = vbslq_u32(mask, d01_orig, maxv);

        sort_01v_ascending(d01);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), vbslq_u32(mask, d01, d01_orig));
    }


    static NOINLINE void sort_02v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d02 = vbslq_u32(mask, d02_orig, maxv);

        sort_02v_ascending(d01, d02);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), vbslq_u32(mask, d02, d02_orig));
    }


    static NOINLINE void sort_03v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d03_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 8));
        uint32x4_t d03 = vbslq_u32(mask, d03_orig, maxv);

        sort_03v_ascending(d01, d02, d03);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), d02);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 8), vbslq_u32(mask, d03, d03_orig));
    }


    static NOINLINE void sort_04v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d03 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 8));
        uint32x4_t d04_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 12));
        uint32x4_t d04 = vbslq_u32(mask, d04_orig, maxv);

        sort_04v_ascending(d01, d02, d03, d04);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), d02);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 8), d03);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 12), vbslq_u32(mask, d04, d04_orig));
    }


    static NOINLINE void sort_05v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d03 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 8));
        uint32x4_t d04 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 12));
        uint32x4_t d05_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 16));
        uint32x4_t d05 = vbslq_u32(mask, d05_orig, maxv);

        sort_05v_ascending(d01, d02, d03, d04, d05);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), d02);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 8), d03);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 12), d04);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 16), vbslq_u32(mask, d05, d05_orig));
    }


    static NOINLINE void sort_06v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d03 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 8));
        uint32x4_t d04 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 12));
        uint32x4_t d05 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 16));
        uint32x4_t d06_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 20));
        uint32x4_t d06 = vbslq_u32(mask, d06_orig, maxv);

        sort_06v_ascending(d01, d02, d03, d04, d05, d06);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), d02);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 8), d03);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 12), d04);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 16), d05);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 20), vbslq_u32(mask, d06, d06_orig));
    }


    static NOINLINE void sort_07v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d03 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 8));
        uint32x4_t d04 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 12));
        uint32x4_t d05 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 16));
        uint32x4_t d06 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 20));
        uint32x4_t d07_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 24));
        uint32x4_t d07 = vbslq_u32(mask, d07_orig, maxv);

        sort_07v_ascending(d01, d02, d03, d04, d05, d06, d07);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), d02);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 8), d03);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 12), d04);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 16), d05);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 20), d06);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 24), vbslq_u32(mask, d07, d07_orig));
    }


    static NOINLINE void sort_08v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d03 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 8));
        uint32x4_t d04 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 12));
        uint32x4_t d05 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 16));
        uint32x4_t d06 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 20));
        uint32x4_t d07 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 24));
        uint32x4_t d08_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 28));
        uint32x4_t d08 = vbslq_u32(mask, d08_orig, maxv);

        sort_08v_ascending(d01, d02, d03, d04, d05, d06, d07, d08);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), d02);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 8), d03);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 12), d04);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 16), d05);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 20), d06);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 24), d07);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 28), vbslq_u32(mask, d08, d08_orig));
    }


    static NOINLINE void sort_09v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d03 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 8));
        uint32x4_t d04 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 12));
        uint32x4_t d05 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 16));
        uint32x4_t d06 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 20));
        uint32x4_t d07 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 24));
        uint32x4_t d08 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 28));
        uint32x4_t d09_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 32));
        uint32x4_t d09 = vbslq_u32(mask, d09_orig, maxv);

        sort_09v_ascending(d01, d02, d03, d04, d05, d06, d07, d08, d09);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), d02);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 8), d03);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 12), d04);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 16), d05);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 20), d06);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 24), d07);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 28), d08);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 32), vbslq_u32(mask, d09, d09_orig));
    }


    static NOINLINE void sort_10v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d03 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 8));
        uint32x4_t d04 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 12));
        uint32x4_t d05 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 16));
        uint32x4_t d06 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 20));
        uint32x4_t d07 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 24));
        uint32x4_t d08 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 28));
        uint32x4_t d09 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 32));
        uint32x4_t d10_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 36));
        uint32x4_t d10 = vbslq_u32(mask, d10_orig, maxv);

        sort_10v_ascending(d01, d02, d03, d04, d05, d06, d07, d08, d09, d10);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), d02);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 8), d03);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 12), d04);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 16), d05);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 20), d06);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 24), d07);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 28), d08);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 32), d09);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 36), vbslq_u32(mask, d10, d10_orig));
    }


    static NOINLINE void sort_11v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d03 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 8));
        uint32x4_t d04 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 12));
        uint32x4_t d05 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 16));
        uint32x4_t d06 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 20));
        uint32x4_t d07 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 24));
        uint32x4_t d08 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 28));
        uint32x4_t d09 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 32));
        uint32x4_t d10 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 36));
        uint32x4_t d11_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 40));
        uint32x4_t d11 = vbslq_u32(mask, d11_orig, maxv);

        sort_11v_ascending(d01, d02, d03, d04, d05, d06, d07, d08, d09, d10, d11);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), d02);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 8), d03);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 12), d04);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 16), d05);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 20), d06);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 24), d07);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 28), d08);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 32), d09);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 36), d10);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 40), vbslq_u32(mask, d11, d11_orig));
    }


    static NOINLINE void sort_12v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d03 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 8));
        uint32x4_t d04 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 12));
        uint32x4_t d05 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 16));
        uint32x4_t d06 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 20));
        uint32x4_t d07 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 24));
        uint32x4_t d08 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 28));
        uint32x4_t d09 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 32));
        uint32x4_t d10 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 36));
        uint32x4_t d11 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 40));
        uint32x4_t d12_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 44));
        uint32x4_t d12 = vbslq_u32(mask, d12_orig, maxv);

        sort_12v_ascending(d01, d02, d03, d04, d05, d06, d07, d08, d09, d10, d11, d12);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), d02);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 8), d03);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 12), d04);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 16), d05);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 20), d06);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 24), d07);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 28), d08);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 32), d09);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 36), d10);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 40), d11);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 44), vbslq_u32(mask, d12, d12_orig));
    }


    static NOINLINE void sort_13v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d03 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 8));
        uint32x4_t d04 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 12));
        uint32x4_t d05 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 16));
        uint32x4_t d06 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 20));
        uint32x4_t d07 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 24));
        uint32x4_t d08 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 28));
        uint32x4_t d09 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 32));
        uint32x4_t d10 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 36));
        uint32x4_t d11 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 40));
        uint32x4_t d12 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 44));
        uint32x4_t d13_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 48));
        uint32x4_t d13 = vbslq_u32(mask, d13_orig, maxv);

        sort_13v_ascending(d01, d02, d03, d04, d05, d06, d07, d08, d09, d10, d11, d12, d13);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), d02);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 8), d03);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 12), d04);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 16), d05);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 20), d06);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 24), d07);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 28), d08);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 32), d09);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 36), d10);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 40), d11);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 44), d12);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 48), vbslq_u32(mask, d13, d13_orig));
    }


    static NOINLINE void sort_14v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d03 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 8));
        uint32x4_t d04 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 12));
        uint32x4_t d05 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 16));
        uint32x4_t d06 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 20));
        uint32x4_t d07 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 24));
        uint32x4_t d08 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 28));
        uint32x4_t d09 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 32));
        uint32x4_t d10 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 36));
        uint32x4_t d11 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 40));
        uint32x4_t d12 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 44));
        uint32x4_t d13 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 48));
        uint32x4_t d14_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 52));
        uint32x4_t d14 = vbslq_u32(mask, d14_orig, maxv);

        sort_14v_ascending(d01, d02, d03, d04, d05, d06, d07, d08, d09, d10, d11, d12, d13, d14);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), d02);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 8), d03);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 12), d04);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 16), d05);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 20), d06);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 24), d07);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 28), d08);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 32), d09);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 36), d10);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 40), d11);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 44), d12);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 48), d13);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 52), vbslq_u32(mask, d14, d14_orig));
    }


    static NOINLINE void sort_15v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d03 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 8));
        uint32x4_t d04 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 12));
        uint32x4_t d05 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 16));
        uint32x4_t d06 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 20));
        uint32x4_t d07 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 24));
        uint32x4_t d08 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 28));
        uint32x4_t d09 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 32));
        uint32x4_t d10 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 36));
        uint32x4_t d11 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 40));
        uint32x4_t d12 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 44));
        uint32x4_t d13 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 48));
        uint32x4_t d14 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 52));
        uint32x4_t d15_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 56));
        uint32x4_t d15 = vbslq_u32(mask, d15_orig, maxv);

        sort_15v_ascending(d01, d02, d03, d04, d05, d06, d07, d08, d09, d10, d11, d12, d13, d14, d15);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), d02);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 8), d03);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 12), d04);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 16), d05);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 20), d06);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 24), d07);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 28), d08);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 32), d09);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 36), d10);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 40), d11);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 44), d12);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 48), d13);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 52), d14);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 56), vbslq_u32(mask, d15, d15_orig));
    }


    static NOINLINE void sort_16v_alt(uint32_t *ptr, int remainder) {
        const uint32x4_t mask = vcltq_u32(idx, vdupq_n_u32(remainder ? remainder : 4));

        uint32x4_t d01 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 0));
        uint32x4_t d02 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 4));
        uint32x4_t d03 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 8));
        uint32x4_t d04 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 12));
        uint32x4_t d05 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 16));
        uint32x4_t d06 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 20));
        uint32x4_t d07 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 24));
        uint32x4_t d08 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 28));
        uint32x4_t d09 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 32));
        uint32x4_t d10 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 36));
        uint32x4_t d11 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 40));
        uint32x4_t d12 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 44));
        uint32x4_t d13 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 48));
        uint32x4_t d14 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 52));
        uint32x4_t d15 = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 56));
        uint32x4_t d16_orig = vld1q_u32(reinterpret_cast<const uint32_t*>(ptr + 60));
        uint32x4_t d16 = vbslq_u32(mask, d16_orig, maxv);

        sort_16v_ascending(d01, d02, d03, d04, d05, d06, d07, d08, d09, d10, d11, d12, d13, d14, d15, d16);

        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 0), d01);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 4), d02);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 8), d03);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 12), d04);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 16), d05);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 20), d06);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 24), d07);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 28), d08);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 32), d09);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 36), d10);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 40), d11);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 44), d12);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 48), d13);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 52), d14);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 56), d15);
        vst1q_u32(reinterpret_cast<uint32_t*>(ptr + 60), vbslq_u32(mask, d16, d16_orig));
    }

    static void sort(uint32_t *ptr, size_t length);

};
}
}

#endif // BITONIC_SORT_NEON

    
